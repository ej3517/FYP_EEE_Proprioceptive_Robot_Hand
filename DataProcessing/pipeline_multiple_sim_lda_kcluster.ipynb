{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "demographic-union",
   "metadata": {},
   "source": [
    "# PIPELINE MULTIPLE SIMULATION-K MEANS CLUSTERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cathedral-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "np.set_printoptions(precision=4)\n",
    "sns.set()\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-spray",
   "metadata": {},
   "source": [
    "# Plotting functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supposed-tonight",
   "metadata": {},
   "source": [
    "## Plot the positions of the finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "static-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def plot_pos_fingers(sides_pos,corners_pos,dim,pose,gap):        \n",
    "        SMALL_SIZE = 8\n",
    "        MEDIUM_SIZE = 20\n",
    "        BIGGER_SIZE = 30\n",
    "\n",
    "        plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "        plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "        plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "        plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "        plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "        plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.style.use(\"ggplot\")\n",
    "        plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "        plt.scatter(sides_pos.T[0],sides_pos.T[1],color='b',marker='+',label='sides')\n",
    "        plt.scatter(corners_pos.T[0],corners_pos.T[1],color='r',marker='+',label='corners')\n",
    "        plt.ylabel(r'$\\theta_R$')\n",
    "        plt.xlabel(r'$\\theta_L$')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title(\"Raw data: dim=\"+str(dim)+'x'+str(dim)+ 'mm ; pose='+str(pose)+'mm ; gap='+str(gap)+'mm',fontsize=20)\n",
    "        #plt.savefig('raw_data_dim'+str(dim)+'x'+str(dim)+ '_pose_'+str(pose)+'_gap_'+str(gap)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-commander",
   "metadata": {},
   "source": [
    "## Plot projection on feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modern-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proj_ld1(lda_X,y,dim,pose,gap):\n",
    "            SMALL_SIZE = 8\n",
    "            MEDIUM_SIZE = 20\n",
    "            BIGGER_SIZE = 30\n",
    "\n",
    "            plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "            plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "            plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "            plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "            plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "            ax.axes.yaxis.set_ticks([])\n",
    "            plt.ylabel('LD1')\n",
    "            plt.scatter(lda_X[y==0], np.full((len(lda_X[y==0]),),1.0), s=100, color='b', label='corner')\n",
    "            plt.scatter(lda_X[y==1], np.full((len(lda_X[y==1]),),1.0), s=100, color='r', label='side')\n",
    "            plt.plot([-1.4,-1.4],[0.9,1.1],'--',color='g')\n",
    "            plt.ylim(0.9,1.1)\n",
    "            ax.legend()\n",
    "            plt.title(\"1D LDA: dim=\"+str(dim)+'x'+str(dim)+ 'mm ; pose='+str(pose)+'mm ; gap='+str(gap)+'mm',fontsize=20)\n",
    "            #plt.savefig('1D_LDA_proj_dim'+str(dim)+'x'+str(dim)+ '_pose_'+str(pose)+'_gap_'+str(gap)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "focused-poker",
   "metadata": {},
   "source": [
    "## 2-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "threatened-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld1_2means(lda_X,y,y_k2means,dim,pose,gap):\n",
    "            SMALL_SIZE = 8\n",
    "            MEDIUM_SIZE = 20\n",
    "            BIGGER_SIZE = 30\n",
    "\n",
    "            plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "            plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "            plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "            plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "            plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "            ax.axes.yaxis.set_ticks([])\n",
    "            plt.ylabel('LD1 & 2-means clustering')\n",
    "            plt.scatter(lda_X[y==0], np.full((len(lda_X[y==0]),),2), color='orange', label='corner')\n",
    "            plt.scatter(lda_X[y==1], np.full((len(lda_X[y==1]),),2), color='purple', label='side')\n",
    "            plt.scatter(lda_X[y_k2means==0], np.full((len(lda_X[y_k2means==0]),),1.0), c='red', label ='Cluster 1')\n",
    "            plt.scatter(lda_X[y_k2means==1], np.full((len(lda_X[y_k2means==1]),),1.0), c='blue', label ='Cluster 2')\n",
    "            plt.scatter(k2means.cluster_centers_[:, 0], np.full((len(k2means.cluster_centers_[:, 0]),),1.0), \n",
    "                        s=100, c='yellow', marker='x',label = 'Centroids')\n",
    "            plt.plot([-1.4,-1.4],[0,4],'--',color='g')\n",
    "            plt.ylim(0,4)\n",
    "            ax.legend()\n",
    "            plt.title(\"LD1 & 2-means: dim=\"+str(dim)+'x'+str(dim)+ 'mm ; pose='+str(pose)+'mm ; gap='+str(gap)+'mm',fontsize=20)\n",
    "            #plt.savefig('LD1_2_means_dim'+str(dim)+'x'+str(dim)+ '_pose_'+str(pose)+'_gap_'+str(gap)+'.png')\n",
    "            #Plot the centroid. This time we're going to use the cluster centres  #attribute that returns here the coordinates of the centroid.\n",
    "            \n",
    "            ##########################################################################################\n",
    "\n",
    "def plot_raw_2means(sides_pos,corners_pos,angle_array,half_window_size,y_k2means,dim,pose,gap):\n",
    "            plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "            plt.scatter(sides_pos.T[0],sides_pos.T[1]+5,color='purple',marker='+',label='sides')\n",
    "            plt.scatter(corners_pos.T[0],corners_pos.T[1]+5,color='orange',marker='+',label='corners')\n",
    "            plt.scatter(angle_array[half_window_size:-half_window_size].T[0][y_k2means == 0], \n",
    "                        angle_array[half_window_size:-half_window_size].T[1][y_k2means == 0]-5, \n",
    "                        marker='+', c='red', label ='Cluster 1')\n",
    "            plt.scatter(angle_array[half_window_size:-half_window_size].T[0][y_k2means == 1], \n",
    "                        angle_array[half_window_size:-half_window_size].T[1][y_k2means == 1]-5, \n",
    "                        marker='+', c='blue', label ='Cluster 2')\n",
    "            plt.plot(angle_array[half_window_size:-half_window_size].T[0],\n",
    "                    angle_array[half_window_size:-half_window_size].T[1],\n",
    "                    color='yellow', label='raw data')\n",
    "            plt.ylabel(r'$\\theta_R$')\n",
    "            plt.xlabel(r'$\\theta_L$')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.title(\"raw data processed (2-means): dim=\"+str(dim)+'x'+str(dim)+ 'mm ; pose='+str(pose)+'mm ; gap='+str(gap)+'mm',fontsize=20)\n",
    "            #plt.savefig('clusters_class_raw_2_means_dim'+str(dim)+'x'+str(dim)+ '_pose_'+str(pose)+'_gap_'+str(gap)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-detection",
   "metadata": {},
   "source": [
    "## 3-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ld1_3means(lda_X,y,y_k3means,dim,pose,gap):\n",
    "            SMALL_SIZE = 8\n",
    "            MEDIUM_SIZE = 20\n",
    "            BIGGER_SIZE = 30\n",
    "\n",
    "            plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "            plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "            plt.rc('axes', labelsize=BIGGER_SIZE)    # fontsize of the x and y labels\n",
    "            plt.rc('xtick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('ytick', labelsize=MEDIUM_SIZE)    # fontsize of the tick labels\n",
    "            plt.rc('legend', fontsize=MEDIUM_SIZE)    # legend fontsize\n",
    "            plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "            ax.axes.yaxis.set_ticks([])\n",
    "            plt.ylabel('LD1 & 3-means clustering')\n",
    "            plt.scatter(lda_X[y==0], np.full((len(lda_X[y==0]),),2), color='orange', label='corner')\n",
    "            plt.scatter(lda_X[y==1], np.full((len(lda_X[y==1]),),2), color='purple', label='side')\n",
    "            plt.scatter(lda_X[y_k3means==0], np.full((len(lda_X[y_k3means==0]),),1.0), c='red', label ='Cluster 1')\n",
    "            plt.scatter(lda_X[y_k3means==1], np.full((len(lda_X[y_k3means==1]),),1.0), c='blue', label ='Cluster 2')\n",
    "            plt.scatter(lda_X[y_k3means==2], np.full((len(lda_X[y_k3means==2]),),1.0), c='green', label ='Cluster 3')\n",
    "            plt.scatter(k3means.cluster_centers_[:, 0], np.full((len(k3means.cluster_centers_[:, 0]),),1.0), \n",
    "                        s=100, c='yellow', marker='x',label = 'Centroids')\n",
    "            plt.plot([-1.4,-1.4],[0,4],'--',color='g')\n",
    "            plt.ylim(0,4)\n",
    "            ax.legend()\n",
    "            plt.title(\"LD1 & 3-means: dim=\"+str(dim)+'x'+str(dim)+ 'mm ; pose='+str(pose)+'mm ; gap='+str(gap)+'mm',fontsize=20)\n",
    "            #plt.savefig('LD1_3_means_dim'+str(dim)+'x'+str(dim)+ '_pose_'+str(pose)+'_gap_'+str(gap)+'.png')\n",
    "\n",
    "            ##########################################################################################\n",
    "\n",
    "def plot_raw_3means(sides_pos,corners_pos,angle_array,half_window_size,y_k3means,dim,pose,gap):\n",
    "            plt.rc('font', size=BIGGER_SIZE)          # controls default text sizes\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.style.use(\"ggplot\")\n",
    "            plt.rcParams[\"figure.figsize\"] = (12,8)\n",
    "            plt.scatter(sides_pos.T[0],sides_pos.T[1]+5,color='purple',marker='+',label='sides')\n",
    "            plt.scatter(corners_pos.T[0],corners_pos.T[1]+5,color='orange',marker='+',label='corners')\n",
    "            plt.scatter(angle_array[half_window_size:-half_window_size].T[0][y_k3means == 0], \n",
    "                        angle_array[half_window_size:-half_window_size].T[1][y_k3means == 0]-5, \n",
    "                        marker='+', c='red', label ='Cluster 1')\n",
    "            plt.scatter(angle_array[half_window_size:-half_window_size].T[0][y_k3means == 1], \n",
    "                        angle_array[half_window_size:-half_window_size].T[1][y_k3means == 1]-5, \n",
    "                        marker='+', c='blue', label ='Cluster 2')\n",
    "            plt.scatter(angle_array[half_window_size:-half_window_size].T[0][y_k3means == 2], \n",
    "                        angle_array[half_window_size:-half_window_size].T[1][y_k3means == 2]-5, \n",
    "                        marker='+', c='green', label ='Cluster 3')\n",
    "            plt.plot(angle_array[half_window_size:-half_window_size].T[0],\n",
    "                    angle_array[half_window_size:-half_window_size].T[1],\n",
    "                    color='yellow', label='raw data')\n",
    "            plt.ylabel(r'$\\theta_R$')\n",
    "            plt.xlabel(r'$\\theta_L$')\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.title(\"raw data processed (3-means): dim=\"+str(dim)+'x'+str(dim)+ 'mm ; pose='+str(pose)+'mm ; gap='+str(gap)+'mm',fontsize=20)\n",
    "            #plt.savefig('clusters_class_raw_3_means_dim'+str(dim)+'x'+str(dim)+ '_pose_'+str(pose)+'_gap_'+str(gap)+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naval-testimony",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "radio-province",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.8333333333333334\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.8909090909090909\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.9090909090909091\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.88\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9565217391304348\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.9090909090909091\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9322033898305084\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9629629629629629\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.9090909090909091\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.92\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.923076923076923\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.96875\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.9090909090909091\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9322033898305084\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.9090909090909091\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9259259259259259\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.923076923076923\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.923076923076923\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9259259259259259\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.8571428571428571\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.94\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9574468085106383\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9322033898305084\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.8571428571428571\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9444444444444444\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.7058823529411764\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.8431372549019608\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.923076923076923\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.923076923076923\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9206349206349206\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.923076923076923\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.923076923076923\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9137931034482759\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.8888888888888888\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.8888888888888888\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9607843137254902\n",
      "The explained variance ratio of lda is :  [1.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1_score of the 2-means is :  0.888888888888889\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9574468085106383\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.8571428571428571\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9322033898305084\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.8\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.631578947368421\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.8148148148148148\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  1.0\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  0.9090909090909091\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.9090909090909091\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9365079365079365\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  0.8571428571428571\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9482758620689655\n",
      "The explained variance ratio of lda is :  [1.]\n",
      "The f1_score of the 2-means is :  1.0\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "The f1_score of the 3-means for global corner identification is :  1.0\n",
      "The f1_score of the 3-means for each corner identification (micro/or accuracy) is :  0.9629629629629629\n",
      "{'dim_20_pose_60_gap_34': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.8333333333333334, 'The f1_score 3-means each corner identification': 0.8909090909090909}, 'dim_25_pose_60_gap_34': {'The f1_score 2-means corner identification': 0.8, 'The f1_score 3-means global corner identification': 0.9090909090909091, 'The f1_score 3-means each corner identification': 0.88}, 'dim_30_pose_60_gap_34': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.9565217391304348}, 'dim_20_pose_60_gap_42': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.9090909090909091, 'The f1_score 3-means each corner identification': 0.9322033898305084}, 'dim_25_pose_60_gap_42': {'The f1_score 2-means corner identification': 0.8, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.9629629629629629}, 'dim_30_pose_60_gap_42': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.9090909090909091, 'The f1_score 3-means each corner identification': 0.92}, 'dim_20_pose_60_gap_50': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 0.923076923076923, 'The f1_score 3-means each corner identification': 0.96875}, 'dim_25_pose_60_gap_50': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.9090909090909091, 'The f1_score 3-means each corner identification': 0.9322033898305084}, 'dim_30_pose_60_gap_50': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.9090909090909091, 'The f1_score 3-means each corner identification': 0.9259259259259259}, 'dim_20_pose_65_gap_34': {'The f1_score 2-means corner identification': 0.923076923076923, 'The f1_score 3-means global corner identification': 0.923076923076923, 'The f1_score 3-means each corner identification': 0.9259259259259259}, 'dim_25_pose_65_gap_34': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 0.8571428571428571, 'The f1_score 3-means each corner identification': 0.94}, 'dim_30_pose_65_gap_34': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.9574468085106383}, 'dim_20_pose_65_gap_42': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.9322033898305084}, 'dim_25_pose_65_gap_42': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.8571428571428571, 'The f1_score 3-means each corner identification': 0.9444444444444444}, 'dim_30_pose_65_gap_42': {'The f1_score 2-means corner identification': 0.8, 'The f1_score 3-means global corner identification': 0.7058823529411764, 'The f1_score 3-means each corner identification': 0.8431372549019608}, 'dim_20_pose_65_gap_50': {'The f1_score 2-means corner identification': 0.923076923076923, 'The f1_score 3-means global corner identification': 0.923076923076923, 'The f1_score 3-means each corner identification': 0.9206349206349206}, 'dim_25_pose_65_gap_50': {'The f1_score 2-means corner identification': 0.923076923076923, 'The f1_score 3-means global corner identification': 0.923076923076923, 'The f1_score 3-means each corner identification': 0.9137931034482759}, 'dim_30_pose_65_gap_50': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.8888888888888888}, 'dim_20_pose_70_gap_34': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.8888888888888888}, 'dim_25_pose_70_gap_34': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.9607843137254902}, 'dim_30_pose_70_gap_34': {'The f1_score 2-means corner identification': 0.888888888888889, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.9574468085106383}, 'dim_20_pose_70_gap_42': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.8571428571428571, 'The f1_score 3-means each corner identification': 0.9322033898305084}, 'dim_25_pose_70_gap_42': {'The f1_score 2-means corner identification': 0.8, 'The f1_score 3-means global corner identification': 0.631578947368421, 'The f1_score 3-means each corner identification': 0.8148148148148148}, 'dim_30_pose_70_gap_42': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 1.0}, 'dim_20_pose_70_gap_50': {'The f1_score 2-means corner identification': 0.9090909090909091, 'The f1_score 3-means global corner identification': 0.9090909090909091, 'The f1_score 3-means each corner identification': 0.9365079365079365}, 'dim_25_pose_70_gap_50': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 0.8571428571428571, 'The f1_score 3-means each corner identification': 0.9482758620689655}, 'dim_30_pose_70_gap_50': {'The f1_score 2-means corner identification': 1.0, 'The f1_score 3-means global corner identification': 1.0, 'The f1_score 3-means each corner identification': 0.9629629629629629}}\n"
     ]
    }
   ],
   "source": [
    "with open('../Simulation/multiple_sqrt_sim_data_pos.json') as f:\n",
    "    full_data_dict = json.load(f)\n",
    "\n",
    "poses_drf = [60,65,70]\n",
    "finger_gaps = [34,42,50]\n",
    "sqrt_sides = [20,25,30]\n",
    "f1_scores = {}\n",
    "\n",
    "for pose in poses_drf:\n",
    "    for gap in finger_gaps:\n",
    "        for dim in sqrt_sides:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            data_dict = full_data_dict[dict_key]\n",
    "\n",
    "            data_list = [data_dict['LF_motion1'],data_dict['RF_motion1']]\n",
    "            data_array = np.array(data_list).T\n",
    "            temp_data_array = np.append(data_array[np.newaxis,0,:,0],data_array[np.newaxis,0,:,1],axis=0)\n",
    "            data_array = np.append(temp_data_array,data_array[np.newaxis,1,:,1],axis=0).T\n",
    "            angle_array = data_array[:,:2].astype(float)\n",
    "\n",
    "            # CREATE A DATAFRAME BY WINDOWING THE RAW AND INCREMENTING THE POSITION OF THE WINDOW\n",
    "            rows,columns = data_array.shape\n",
    "            window_size = 5 # needs to be odd\n",
    "            half_window_size = math.floor(window_size/2)\n",
    "            data_window = np.zeros((rows-half_window_size*2,window_size*2+1)) #+1 for the class\n",
    "            corners = []\n",
    "            sides = []\n",
    "\n",
    "            for i in range(half_window_size,rows-half_window_size):\n",
    "                temp_window = np.append(data_array[i-half_window_size:half_window_size+i+1,:].T[0],\n",
    "                                        data_array[i-half_window_size:half_window_size+i+1,:].T[1])\n",
    "                if 'corner' in data_array[i-half_window_size+1:half_window_size+i+1-1,:].T[2]:\n",
    "                    # CLASS 2 IS THE CORNER\n",
    "                    corners += [angle_array[i].tolist()]\n",
    "                    data_window[i-half_window_size] = np.append(temp_window,np.array([2]))\n",
    "                else :\n",
    "                    # CLASS 1 IS THE SIDE\n",
    "                    sides += [angle_array[i].tolist()]\n",
    "                    data_window[i-half_window_size] = np.append(temp_window,np.array([1]))\n",
    "\n",
    "            #print(data_window)\n",
    "            names = []\n",
    "            for j in range(window_size):\n",
    "                names += [\"angleLF\"+str(j+1)]\n",
    "            for j in range(window_size):\n",
    "                names += [\"angleRF\"+str(j+1)]\n",
    "            names += [\"class\"]\n",
    "\n",
    "            # DATA FRAME PANDAS\n",
    "            df = pd.DataFrame(data=data_window,columns = names)\n",
    "            df[\"class\"].replace({1.0: \"side\", 2.0: \"corner\"}, inplace=True)\n",
    "            df.dropna(how='all', inplace=True)\n",
    "            windows = df[names[:len(names)-1]]\n",
    "            labels = df[names[-1]]\n",
    "\n",
    "            corners_pos = np.array(corners)\n",
    "            sides_pos = np.array(sides)\n",
    "\n",
    "            df.head()\n",
    "\n",
    "            ##########################################################################################\n",
    "            ############################# Plot the positions of the finger ###########################\n",
    "            ##########################################################################################\n",
    "            #plot_pos_fingers(sides_pos,corners_pos,dim,pose,gap)\n",
    "            \n",
    "            ##########################################################################################\n",
    "            ############################# LDA with sklearn ###########################\n",
    "            ##########################################################################################\n",
    "\n",
    "            # Preparation of the data for LDA\n",
    "            X = df.iloc[:, 0:-1].values\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(df['class'])\n",
    "\n",
    "            # Import LDA from sklearn\n",
    "            lda = LinearDiscriminantAnalysis()\n",
    "            lda_X = lda.fit_transform(X, y)\n",
    "            print(\"The explained variance ratio of lda is : \", lda.explained_variance_ratio_)\n",
    "\n",
    "            ##########################################################################################\n",
    "            ############################# Plot projection on feature vectors ###########################\n",
    "            ##########################################################################################\n",
    "            #plot_proj_ld1(lda_X,y,dim,pose,gap)\n",
    "            \n",
    "            ##########################################################################################\n",
    "            #################################### K-means #############################################\n",
    "            ##########################################################################################\n",
    "\n",
    "            # 2-means clustering \n",
    "            k2means = KMeans(n_clusters=2, init ='k-means++', max_iter=300, n_init=10,random_state=0 )\n",
    "            y_k2means = k2means.fit_predict(lda_X)\n",
    "\n",
    "            # 3-mens clustering\n",
    "            k3means = KMeans(n_clusters=3, init ='k-means++', max_iter=300, n_init=10,random_state=0 )\n",
    "            y_k3means = k3means.fit_predict(lda_X)\n",
    "            \n",
    "            ##########################################################################################\n",
    "            #plot_ld1_2means(lda_X,y,y_k2means,dim,pose,gap)\n",
    "            ##########################################################################################\n",
    "            #plot_raw_2means(sides_pos,corners_pos,angle_array,half_window_size,y_k2means,dim,pose,gap)\n",
    "            ##########################################################################################\n",
    "            #plot_ld1_3means(lda_X,y,y_k3means,dim,pose,gap)\n",
    "            ##########################################################################################\n",
    "            #plot_raw_3means(sides_pos,corners_pos,angle_array,half_window_size,y_k3means,dim,pose,gap)\n",
    "            ##########################################################################################\n",
    "            \n",
    "            ##########################################################################################\n",
    "            #################################### F1-score ############################################\n",
    "            ##########################################################################################\n",
    "\n",
    "            # we need to change \"y\" before beca\n",
    "            y_true = []\n",
    "            for i in range(y.shape[0]):\n",
    "                if y[i] == 0:\n",
    "                    y_true += [1]\n",
    "                else:\n",
    "                    y_true += [0]\n",
    "                    \n",
    "            f1_score_2means = f1_score(y_true,y_k2means)\n",
    "            print(\"The f1_score of the 2-means is : \",f1_score_2means)\n",
    "            print(y_true)\n",
    "\n",
    "            # f1-score on just the corner identification\n",
    "            y_k3_corner = []\n",
    "            for i in range(len(y_k3means.tolist())):\n",
    "                if y_k3means[i] == 2:\n",
    "                    y_k3_corner += [1]\n",
    "                else :\n",
    "                    y_k3_corner += [y_k3means[i]]\n",
    "            y_k3_corner = np.array(y_k3_corner)\n",
    "            \n",
    "            f1_score_3means = f1_score(y_true,y_k3_corner)\n",
    "            print(\"The f1_score of the 3-means for global corner identification is : \",f1_score_3means)\n",
    "\n",
    "            # f1-score on the number of corners\n",
    "            u = 0\n",
    "            v = 0\n",
    "            y_true_corners = []\n",
    "            for i in range(len(y_true)):\n",
    "                if y_true[i] == 1 and v == 0:\n",
    "                    y_true_corners += [y_true[i]]\n",
    "                    u = 1\n",
    "                elif y_true[i] == 0 and u==1:\n",
    "                    y_true_corners += [y_true[i]]\n",
    "                    v = 1\n",
    "                elif y_true[i] == 1 and v==1:\n",
    "                    y_true_corners += [2]\n",
    "                else:\n",
    "                    y_true_corners += [y_true[i]]\n",
    "            acc_3means = accuracy_score(y_true_corners,y_k3means)\n",
    "            print(\"The f1_score of the 3-means for each corner identification (micro/or accuracy) is : \",\n",
    "                  acc_3means)\n",
    "            \n",
    "            f1_scores[dict_key] = {\n",
    "                \"The f1_score 2-means corner identification\" : f1_score_2means,\n",
    "                \"The f1_score 3-means global corner identification\" : f1_score_3means,\n",
    "                \"The f1_score 3-means each corner identification\" : acc_3means      \n",
    "            }\n",
    "            \n",
    "print(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ongoing-produce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f1_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7524cf51bca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_scores_sqrt_dim_w_5.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mindent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m  \u001b[0;31m# is not needed but makes the file human-readable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'f1_scores' is not defined"
     ]
    }
   ],
   "source": [
    "# !!!!!!!!!!!!! this can wipe out the file !!!!!!!!!!!!\n",
    "with open(\"f1_scores_sqrt_dim_w_5.json\", 'w') as f:\n",
    "    indent = 2  # is not needed but makes the file human-readable\n",
    "    json.dump(f1_scores, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-houston",
   "metadata": {},
   "source": [
    "# Create a table with the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "collaborative-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TABLE 1 \n",
      "\n",
      "DIMENSION    POSE         GAP          F1 2-Means   F1 3-Means   F1 3-Means (each)\n",
      "20           60           34           60           0.909        0.833       \n",
      "25           60           34           60           0.8          0.909       \n",
      "30           60           34           60           1.0          1.0         \n",
      "20           65           34           65           0.923        0.923       \n",
      "25           65           34           65           1.0          0.857       \n",
      "30           65           34           65           1.0          1.0         \n",
      "20           70           34           70           1.0          1.0         \n",
      "25           70           34           70           1.0          1.0         \n",
      "30           70           34           70           0.889        1.0         \n",
      "20           60           42           60           0.909        0.909       \n",
      "25           60           42           60           0.8          1.0         \n",
      "30           60           42           60           0.909        0.909       \n",
      "20           65           42           65           1.0          1.0         \n",
      "25           65           42           65           0.909        0.857       \n",
      "30           65           42           65           0.8          0.706       \n",
      "20           70           42           70           0.909        0.857       \n",
      "25           70           42           70           0.8          0.632       \n",
      "30           70           42           70           1.0          1.0         \n",
      "20           60           50           60           1.0          0.923       \n",
      "25           60           50           60           0.909        0.909       \n",
      "30           60           50           60           0.909        0.909       \n",
      "20           65           50           65           0.923        0.923       \n",
      "25           65           50           65           0.923        0.923       \n",
      "30           65           50           65           1.0          1.0         \n",
      "20           70           50           70           0.909        0.909       \n",
      "25           70           50           70           1.0          0.857       \n",
      "30           70           50           70           1.0          1.0         \n",
      "\n",
      "TABLE 2 \n",
      "\n",
      "DIMENSION    POSE         GAP          F1 2-Means   F1 3-Means   F1 3-Means (each)\n",
      "20           60           34           60           0.909        0.833       \n",
      "25           60           34           60           0.8          0.909       \n",
      "30           60           34           60           1.0          1.0         \n",
      "20           60           42           60           0.909        0.909       \n",
      "25           60           42           60           0.8          1.0         \n",
      "30           60           42           60           0.909        0.909       \n",
      "20           60           50           60           1.0          0.923       \n",
      "25           60           50           60           0.909        0.909       \n",
      "30           60           50           60           0.909        0.909       \n",
      "20           65           34           65           0.923        0.923       \n",
      "25           65           34           65           1.0          0.857       \n",
      "30           65           34           65           1.0          1.0         \n",
      "20           65           42           65           1.0          1.0         \n",
      "25           65           42           65           0.909        0.857       \n",
      "30           65           42           65           0.8          0.706       \n",
      "20           65           50           65           0.923        0.923       \n",
      "25           65           50           65           0.923        0.923       \n",
      "30           65           50           65           1.0          1.0         \n",
      "20           70           34           70           1.0          1.0         \n",
      "25           70           34           70           1.0          1.0         \n",
      "30           70           34           70           0.889        1.0         \n",
      "20           70           42           70           0.909        0.857       \n",
      "25           70           42           70           0.8          0.632       \n",
      "30           70           42           70           1.0          1.0         \n",
      "20           70           50           70           0.909        0.909       \n",
      "25           70           50           70           1.0          0.857       \n",
      "30           70           50           70           1.0          1.0         \n",
      "\n",
      "TABLE 3 \n",
      "\n",
      "DIMENSION    POSE         GAP          F1 2-Means   F1 3-Means   F1 3-Means (each)\n",
      "20           60           34           60           0.909        0.833       \n",
      "20           65           34           65           0.923        0.923       \n",
      "20           70           34           70           1.0          1.0         \n",
      "20           60           42           60           0.909        0.909       \n",
      "20           65           42           65           1.0          1.0         \n",
      "20           70           42           70           0.909        0.857       \n",
      "20           60           50           60           1.0          0.923       \n",
      "20           65           50           65           0.923        0.923       \n",
      "20           70           50           70           0.909        0.909       \n",
      "25           60           34           60           0.8          0.909       \n",
      "25           65           34           65           1.0          0.857       \n",
      "25           70           34           70           1.0          1.0         \n",
      "25           60           42           60           0.8          1.0         \n",
      "25           65           42           65           0.909        0.857       \n",
      "25           70           42           70           0.8          0.632       \n",
      "25           60           50           60           0.909        0.909       \n",
      "25           65           50           65           0.923        0.923       \n",
      "25           70           50           70           1.0          0.857       \n",
      "30           60           34           60           1.0          1.0         \n",
      "30           65           34           65           1.0          1.0         \n",
      "30           70           34           70           0.889        1.0         \n",
      "30           60           42           60           0.909        0.909       \n",
      "30           65           42           65           0.8          0.706       \n",
      "30           70           42           70           1.0          1.0         \n",
      "30           60           50           60           0.909        0.909       \n",
      "30           65           50           65           1.0          1.0         \n",
      "30           70           50           70           1.0          1.0         \n"
     ]
    }
   ],
   "source": [
    "with open('f1_scores_sqrt_dim_new_w_5.json') as f:\n",
    "    dict_f1 = json.load(f)\n",
    "\n",
    "poses_drf = [60,65,70]\n",
    "finger_gaps = [34,42,50]\n",
    "sqrt_sides = [20,25,30]\n",
    "\n",
    "print(\"\\nTABLE 1 \\n\")\n",
    "# Print the names of the columns.\n",
    "print (\"{:<12} {:<12} {:<12} {:<12} {:<12} {:<12}\".format('DIMENSION', 'POSE', 'GAP', 'F1 2-Means','F1 3-Means','F1 3-Means (each)'))\n",
    "\n",
    "# print each data item.\n",
    "for gap in finger_gaps:\n",
    "    for pose in poses_drf:\n",
    "        for dim in sqrt_sides:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            dict_value = dict_f1[dict_key]\n",
    "            f1_2means = round(dict_value['The f1_score 2-means corner identification'],3)\n",
    "            f1_3means_glob = round(dict_value['The f1_score 3-means global corner identification'],3)\n",
    "            f1_3means_each = round(dict_value['The f1_score 3-means each corner identification'],3)\n",
    "            print (\"{:<12} {:<12} {:<12} {:<12} {:<12} {:<12}\".format(dim,pose,gap,pose,f1_2means, f1_3means_glob, f1_3means_each))\n",
    "\n",
    "\n",
    "print(\"\\nTABLE 2 \\n\")\n",
    "# Print the names of the columns.\n",
    "print (\"{:<12} {:<12} {:<12} {:<12} {:<12} {:<12}\".format('DIMENSION', 'POSE', 'GAP', 'F1 2-Means','F1 3-Means','F1 3-Means (each)'))\n",
    "\n",
    "for pose in poses_drf:\n",
    "    for gap in finger_gaps:\n",
    "        for dim in sqrt_sides:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            dict_value = dict_f1[dict_key]\n",
    "            f1_2means = round(dict_value['The f1_score 2-means corner identification'],3)\n",
    "            f1_3means_glob = round(dict_value['The f1_score 3-means global corner identification'],3)\n",
    "            f1_3means_each = round(dict_value['The f1_score 3-means each corner identification'],3)\n",
    "            print (\"{:<12} {:<12} {:<12} {:<12} {:<12} {:<12}\".format(dim,pose,gap,pose,f1_2means, f1_3means_glob, f1_3means_each))\n",
    "\n",
    "\n",
    "print(\"\\nTABLE 3 \\n\")\n",
    "# Print the names of the columns.\n",
    "print (\"{:<12} {:<12} {:<12} {:<12} {:<12} {:<12}\".format('DIMENSION', 'POSE', 'GAP', 'F1 2-Means','F1 3-Means','F1 3-Means (each)'))\n",
    "\n",
    "for dim in sqrt_sides:\n",
    "    for gap in finger_gaps:\n",
    "        for pose in poses_drf:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            dict_value = dict_f1[dict_key]\n",
    "            f1_2means = round(dict_value['The f1_score 2-means corner identification'],3)\n",
    "            f1_3means_glob = round(dict_value['The f1_score 3-means global corner identification'],3)\n",
    "            f1_3means_each = round(dict_value['The f1_score 3-means each corner identification'],3)\n",
    "            print (\"{:<12} {:<12} {:<12} {:<12} {:<12} {:<12}\".format(dim,pose,gap,pose,f1_2means, f1_3means_glob, f1_3means_each))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-lotus",
   "metadata": {},
   "source": [
    "# Calculate the average f1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "warming-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAME SIZE \n",
      "\n",
      "The average f1-score for squares of dim = 20  and 2-means clustering :  0.9424444444444444\n",
      "The average f1-score for squares of dim = 20  and 3-means clustering :  0.9196666666666667\n",
      "The average accuracy for squares of dim = 20  and 3-means clustering :  0.9254444444444445 \n",
      "\n",
      "The average f1-score for squares of dim = 25  and 2-means clustering :  0.9045555555555553\n",
      "The average f1-score for squares of dim = 25  and 3-means clustering :  0.8826666666666667\n",
      "The average accuracy for squares of dim = 25  and 3-means clustering :  0.921888888888889 \n",
      "\n",
      "The average f1-score for squares of dim = 30  and 2-means clustering :  0.9452222222222222\n",
      "The average f1-score for squares of dim = 30  and 3-means clustering :  0.9471111111111112\n",
      "The average accuracy for squares of dim = 30  and 3-means clustering :  0.9346666666666668 \n",
      "\n",
      "\n",
      "SAME POSE \n",
      "\n",
      "The average f1-score for squares with pose = 60  and 2-means clustering :  0.9049999999999999\n",
      "The average f1-score for squares with pose = 60  and 3-means clustering :  0.9223333333333333\n",
      "The average accuracy for squares with pose = 60  and 3-means clustering :  0.9299999999999999 \n",
      "\n",
      "The average f1-score for squares with pose = 65  and 2-means clustering :  0.942\n",
      "The average f1-score for squares with pose = 65  and 3-means clustering :  0.9098888888888889\n",
      "The average accuracy for squares with pose = 65  and 3-means clustering :  0.9184444444444444 \n",
      "\n",
      "The average f1-score for squares with pose = 70  and 2-means clustering :  0.9452222222222224\n",
      "The average f1-score for squares with pose = 70  and 3-means clustering :  0.9172222222222222\n",
      "The average accuracy for squares with pose = 70  and 3-means clustering :  0.9335555555555555 \n",
      "\n",
      "\n",
      "SAME GAP \n",
      "\n",
      "\n",
      "The average f1-score for squares with fingers gap = 34  and 2-means clustering :  0.9467777777777777\n",
      "The average f1-score for squares with fingers gap = 34  and 3-means clustering :  0.9468888888888889\n",
      "The average accuracy for squares with fingers gap = 34  and 3-means clustering :  0.9286666666666668 \n",
      "\n",
      "The average f1-score for squares with fingers gap = 42  and 2-means clustering :  0.8928888888888888\n",
      "The average f1-score for squares with fingers gap = 42  and 3-means clustering :  0.8744444444444444\n",
      "The average accuracy for squares with fingers gap = 42  and 3-means clustering :  0.9201111111111112 \n",
      "\n",
      "The average f1-score for squares with fingers gap = 50  and 2-means clustering :  0.9525555555555556\n",
      "The average f1-score for squares with fingers gap = 50  and 3-means clustering :  0.9281111111111111\n",
      "The average accuracy for squares with fingers gap = 50  and 3-means clustering :  0.9332222222222223 \n",
      "\n",
      "\n",
      "TOTAL AVERAGE \n",
      "\n",
      "\n",
      "The total average f1-score for squares and 2-means clustering :  0.9307407407407409\n",
      "The total average f1-score for squares and 3-means clustering :  0.9164814814814813\n",
      "The total average accuracy for squares and 3-means clustering :  0.9273333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('f1_scores_sqrt_dim_new_w_5.json') as f:\n",
    "    dict_f1 = json.load(f)\n",
    "\n",
    "poses_drf = [60,65,70]\n",
    "finger_gaps = [34,42,50]\n",
    "sqrt_sides = [20,25,30]\n",
    "\n",
    "path = 'f1_scores_sqrt_dim_new_w_5.txt'\n",
    "f1_file = open(path,'w')\n",
    "\n",
    "title = 'All the F1-score and accuracy of the squares simulation for window of size 5 \\n'\n",
    "f1_file.write(title)\n",
    "\n",
    "\n",
    "################ same size ################ \n",
    "f1_file.write('\\nSAME SIZE \\n\\n')\n",
    "print('\\nSAME SIZE \\n')\n",
    "\n",
    "sum_f1_score_2means = 0\n",
    "sum_f1_score_3means_glob = 0\n",
    "sum_f1_score_3means_each = 0\n",
    "nb_f1_Scores = 0\n",
    "for dim in sqrt_sides:\n",
    "    for gap in finger_gaps:\n",
    "        for pose in poses_drf:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            dict_value = dict_f1[dict_key]\n",
    "            f1_2means = round(dict_value['The f1_score 2-means corner identification'],3)\n",
    "            f1_3means_glob = round(dict_value['The f1_score 3-means global corner identification'],3)\n",
    "            f1_3means_each = round(dict_value['The f1_score 3-means each corner identification'],3)\n",
    "            sum_f1_score_2means += f1_2means\n",
    "            sum_f1_score_3means_glob += f1_3means_glob\n",
    "            sum_f1_score_3means_each += f1_3means_each\n",
    "            nb_f1_Scores += 1\n",
    "    print('The average f1-score for squares of dim =',str(dim),' and 2-means clustering : ',sum_f1_score_2means/nb_f1_Scores)\n",
    "    f1_file.write('The average f1-score for squares of dim ='+str(dim)+' and 2-means clustering : '+str(sum_f1_score_2means/nb_f1_Scores)+'\\n')\n",
    "    print('The average f1-score for squares of dim =',str(dim),' and 3-means clustering : ',sum_f1_score_3means_glob/nb_f1_Scores)\n",
    "    f1_file.write('The average f1-score for squares of dim ='+str(dim)+' and 3-means clustering : '+str(sum_f1_score_3means_glob/nb_f1_Scores)+'\\n')\n",
    "    print('The average accuracy for squares of dim =',str(dim),' and 3-means clustering : ',sum_f1_score_3means_each/nb_f1_Scores,'\\n')\n",
    "    f1_file.write('The average accuracy for squares of dim ='+str(dim)+' and 3-means clustering : '+str(sum_f1_score_3means_each/nb_f1_Scores)+'\\n\\n')\n",
    "    sum_f1_score_2means = 0\n",
    "    sum_f1_score_3means_glob = 0\n",
    "    sum_f1_score_3means_each = 0\n",
    "    nb_f1_Scores = 0\n",
    "    \n",
    "\n",
    "################ same pose ################ \n",
    "print('\\nSAME POSE \\n')\n",
    "f1_file.write('\\nSAME POSE \\n\\n')\n",
    "sum_f1_score_2means = 0\n",
    "sum_f1_score_2means_glob = 0\n",
    "sum_f1_score_2means_each = 0\n",
    "nb_f1_Scores = 0\n",
    "for pose in poses_drf:\n",
    "    for dim in sqrt_sides:\n",
    "        for gap in finger_gaps:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            dict_value = dict_f1[dict_key]\n",
    "            f1_2means = round(dict_value['The f1_score 2-means corner identification'],3)\n",
    "            f1_3means_glob = round(dict_value['The f1_score 3-means global corner identification'],3)\n",
    "            f1_3means_each = round(dict_value['The f1_score 3-means each corner identification'],3)\n",
    "            sum_f1_score_2means += f1_2means\n",
    "            sum_f1_score_3means_glob += f1_3means_glob\n",
    "            sum_f1_score_3means_each += f1_3means_each\n",
    "            nb_f1_Scores += 1\n",
    "    print('The average f1-score for squares with pose =',str(pose),' and 2-means clustering : ',sum_f1_score_2means/nb_f1_Scores)\n",
    "    f1_file.write('The average f1-score for squares with pose ='+str(pose)+' and 2-means clustering : '+str(sum_f1_score_2means/nb_f1_Scores)+'\\n')\n",
    "    print('The average f1-score for squares with pose =',str(pose),' and 3-means clustering : ',sum_f1_score_3means_glob/nb_f1_Scores)\n",
    "    f1_file.write('The average f1-score for squares with pose ='+str(pose)+' and 3-means clustering : '+str(sum_f1_score_3means_glob/nb_f1_Scores)+'\\n')\n",
    "    print('The average accuracy for squares with pose =',str(pose),' and 3-means clustering : ',sum_f1_score_3means_each/nb_f1_Scores,'\\n')\n",
    "    f1_file.write('The average accuracy for squares with pose ='+str(pose)+' and 3-means clustering : '+str(sum_f1_score_3means_each/nb_f1_Scores)+'\\n\\n')\n",
    "    sum_f1_score_2means = 0\n",
    "    sum_f1_score_3means_glob = 0\n",
    "    sum_f1_score_3means_each = 0\n",
    "    nb_f1_Scores = 0\n",
    "\n",
    "\n",
    "################ same gap ################ \n",
    "f1_file.write('\\nSAME GAP \\n\\n')\n",
    "print('\\nSAME GAP \\n\\n')\n",
    "sum_f1_score_2means = 0\n",
    "sum_f1_score_2means_glob = 0\n",
    "sum_f1_score_2means_each = 0\n",
    "nb_f1_Scores = 0\n",
    "for gap in finger_gaps:\n",
    "    for dim in sqrt_sides:\n",
    "        for pose in poses_drf:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            dict_value = dict_f1[dict_key]\n",
    "            f1_2means = round(dict_value['The f1_score 2-means corner identification'],3)\n",
    "            f1_3means_glob = round(dict_value['The f1_score 3-means global corner identification'],3)\n",
    "            f1_3means_each = round(dict_value['The f1_score 3-means each corner identification'],3)\n",
    "            sum_f1_score_2means += f1_2means\n",
    "            sum_f1_score_3means_glob += f1_3means_glob\n",
    "            sum_f1_score_3means_each += f1_3means_each\n",
    "            nb_f1_Scores += 1\n",
    "    print('The average f1-score for squares with fingers gap =',str(gap),' and 2-means clustering : ',sum_f1_score_2means/nb_f1_Scores)\n",
    "    f1_file.write('The average f1-score for squares with fingers gap ='+str(gap)+' and 2-means clustering : '+str(sum_f1_score_2means/nb_f1_Scores)+'\\n')\n",
    "    print('The average f1-score for squares with fingers gap =',str(gap),' and 3-means clustering : ',sum_f1_score_3means_glob/nb_f1_Scores)\n",
    "    f1_file.write('The average f1-score for squares with fingers gap ='+str(gap)+' and 3-means clustering : '+str(sum_f1_score_3means_glob/nb_f1_Scores)+'\\n')\n",
    "    print('The average accuracy for squares with fingers gap =',str(gap),' and 3-means clustering : ',sum_f1_score_3means_each/nb_f1_Scores,'\\n')\n",
    "    f1_file.write('The average accuracy for squares with fingers gap ='+str(gap)+' and 3-means clustering : '+str(sum_f1_score_3means_each/nb_f1_Scores)+'\\n\\n')\n",
    "    sum_f1_score_2means = 0\n",
    "    sum_f1_score_3means_glob = 0\n",
    "    sum_f1_score_3means_each = 0\n",
    "    nb_f1_Scores = 0\n",
    "\n",
    "################ total average ################ \n",
    "f1_file.write('\\nTOTAL AVERAGE \\n\\n')\n",
    "print('\\nTOTAL AVERAGE \\n\\n')\n",
    "sum_f1_score_2means = 0\n",
    "sum_f1_score_3means_glob = 0\n",
    "sum_f1_score_3means_each = 0\n",
    "nb_f1_Scores = 0\n",
    "for gap in finger_gaps:\n",
    "    for dim in sqrt_sides:\n",
    "        for pose in poses_drf:\n",
    "            dict_key = \"dim_\"+str(dim)+\"_pose_\"+str(pose)+\"_gap_\"+str(gap)\n",
    "            dict_value = dict_f1[dict_key]\n",
    "            f1_2means = round(dict_value['The f1_score 2-means corner identification'],3)\n",
    "            f1_3means_glob = round(dict_value['The f1_score 3-means global corner identification'],3)\n",
    "            f1_3means_each = round(dict_value['The f1_score 3-means each corner identification'],3)\n",
    "            sum_f1_score_2means += f1_2means\n",
    "            sum_f1_score_3means_glob += f1_3means_glob\n",
    "            sum_f1_score_3means_each += f1_3means_each\n",
    "            nb_f1_Scores += 1\n",
    "print('The total average f1-score for squares and 2-means clustering : ',sum_f1_score_2means/nb_f1_Scores)\n",
    "f1_file.write('The total average f1-score for squares and 2-means clustering : '+str(sum_f1_score_2means/nb_f1_Scores)+'\\n')\n",
    "print('The total average f1-score for squares and 3-means clustering : ',sum_f1_score_3means_glob/nb_f1_Scores)\n",
    "f1_file.write('The total average f1-score for squares and 3-means clustering : '+str(sum_f1_score_3means_glob/nb_f1_Scores)+'\\n')\n",
    "print('The total average accuracy for squares and 3-means clustering : ',sum_f1_score_3means_each/nb_f1_Scores,'\\n')\n",
    "f1_file.write('The total average accuracy for squares and 3-means clustering : '+str(sum_f1_score_3means_each/nb_f1_Scores)+'\\n\\n')\n",
    "\n",
    "f1_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-discharge",
   "metadata": {},
   "source": [
    "- poor performance for the small square for the 3-means as the window of are overlapping \n",
    "- for gap 42 problems\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
